// Fix for import issues: Use default import and destructure
// We support both 'Client' (standard) and 'GoogleGenAI' (legacy/alias) class names
import genai from "npm:@google/genai";

// Set environment variable for Vertex AI mode as requested by user
try {
  Deno.env.set("GOOGLE_GENAI_USE_VERTEXAI", "true");
} catch (e) {
  // Ignore
}

// Destructure safely
const Client = genai.Client || genai.GoogleGenAI;

export async function speechToText(audioBase64: string): Promise<string> {
  console.log('ğŸ¤ Starting speech recognition (SDK Mode - @google/genai)...');

  try {
    const apiKey = Deno.env.get("vertex_api_key");
    if (!apiKey) {
      throw new Error("Missing 'vertex_api_key' environment variable.");
    }

    // Initialize Client
    if (!Client) {
        console.error("Available exports in @google/genai:", Object.keys(genai));
        throw new Error("Google GenAI Client class not found in package exports.");
    }

    // Use vertexai: true in constructor explicitly as well
    const client = new Client({
        vertexai: true,
        apiKey: apiKey,
        httpOptions: { apiVersion: "v1beta" }
    });

    // Call Gemini 3.0 Pro Preview
    const response = await client.models.generateContent({
      model: "gemini-3-pro-preview",
      contents: [{
        role: "user",
        parts: [
          { text: 'è¯·å°†è¿™æ®µéŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—ã€‚åªè¾“å‡ºè¯†åˆ«å‡ºçš„æ–‡å­—å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–è¯´æ˜ã€‚å¦‚æœæ˜¯ä¸­æ–‡ï¼Œè¯·è¾“å‡ºä¸­æ–‡ã€‚' },
          { inlineData: { mimeType: 'audio/webm', data: audioBase64 } }
        ]
      }]
    });

    // Extract text
    const text = response.text || 
                 (response.candidates && response.candidates[0]?.content?.parts?.[0]?.text) || 
                 "";
                 
    console.log('ğŸ“ STT Result:', text.substring(0, 50));
    return text.trim();

  } catch (error) {
    console.error('âŒ STT Error:', error);
    throw error;
  }
}
